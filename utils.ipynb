{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class strLabelConverter(object):\n",
    "    \"\"\"Convert between str and label.\n",
    "\n",
    "    NOTE:\n",
    "        Insert `blank` to the alphabet for CTC.\n",
    "\n",
    "    Args:\n",
    "        alphabet (str): set of the possible characters.\n",
    "        ignore_case (bool, default=True): whether or not to ignore all of the case.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alphabet, ignore_case=True):\n",
    "        self._ignore_case = ignore_case\n",
    "        if self._ignore_case:\n",
    "            alphabet = alphabet.lower()\n",
    "        self.alphabet = alphabet + '-'  # for last index\n",
    "\n",
    "        self.dict = {}\n",
    "        for i, char in enumerate(alphabet):\n",
    "            # NOTE: 0 is reserved for 'blank' required by wrap_ctc\n",
    "            self.dict[char] = i + 1 # initialized coding for dictionary used\n",
    "\n",
    "    def encode(self, text):\n",
    "        \"\"\"Support batch or single str.\n",
    "\n",
    "        Args:\n",
    "            text (str or list of str): texts to convert.\n",
    "\n",
    "        Returns:\n",
    "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\n",
    "            torch.IntTensor [n]: length of each text.\n",
    "        \"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = [\n",
    "                self.dict[char.lower() if self._ignore_case else char]\n",
    "                for char in text\n",
    "            ]\n",
    "            length = [len(text)]\n",
    "        elif isinstance(text, collections.Iterable):\n",
    "            length = [len(s) for s in text]\n",
    "            text = ''.join(text)\n",
    "            text, _ = self.encode(text)\n",
    "        return (torch.IntTensor(text), torch.IntTensor(length))\n",
    "\n",
    "    def decode(self, t, length, raw=False):\n",
    "        \"\"\"Decode encoded texts back into strs.\n",
    "\n",
    "        Args:\n",
    "            torch.IntTensor [length_0 + length_1 + ... length_{n - 1}]: encoded texts.\n",
    "            torch.IntTensor [n]: length of each text.\n",
    "\n",
    "        Raises:\n",
    "            AssertionError: when the texts and its length does not match.\n",
    "\n",
    "        Returns:\n",
    "            text (str or list of str): texts to convert.\n",
    "        \"\"\"\n",
    "        if length.numel() == 1:\n",
    "            length = length[0]\n",
    "            assert t.numel() == length, \"text with length: {} does not match declared length: {}\".format(t.numel(), length)\n",
    "            if raw:\n",
    "                return ''.join([self.alphabet[i - 1] for i in t])\n",
    "            else:\n",
    "                char_list = []\n",
    "                for i in range(length):\n",
    "                    if t[i] != 0 and (not (i > 0 and t[i - 1] == t[i])):\n",
    "                        char_list.append(self.alphabet[t[i] - 1])\n",
    "                return ''.join(char_list)\n",
    "        else:\n",
    "            # batch mode\n",
    "            assert t.numel() == length.sum(), \"texts with length: {} does not match declared length: {}\".format(t.numel(), length.sum())\n",
    "            texts = []\n",
    "            index = 0\n",
    "            for i in range(length.numel()):\n",
    "                l = length[i]\n",
    "                texts.append(\n",
    "                    self.decode(\n",
    "                        t[index:index + l], torch.IntTensor([l]), raw=raw))\n",
    "                index += l\n",
    "            return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'abcdefg'\n",
    "\n",
    "samples = ['abb', 'cee', 'fga']\n",
    "\n",
    "converter = strLabelConverter(alphabet=alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YUNJIE~1\\AppData\\Local\\Temp/ipykernel_66860/3387093810.py:39: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  elif isinstance(text, collections.Iterable):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 2, 3, 5, 5, 6, 7, 1], dtype=torch.int32),\n",
       " tensor([3, 3, 3], dtype=torch.int32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter.encode(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class labelConverter(object):\n",
    "\n",
    "    def __init__(self, alphabet):\n",
    "        self.dict = {}\n",
    "        for i, char in enumerate(alphabet):\n",
    "            self.dict[char] = i + 1\n",
    "\n",
    "        self.dict[''] = 0\n",
    "\n",
    "    def encode(self, text):\n",
    "        '''Convert list of strings to label seq'''\n",
    "        length=[]\n",
    "        seq=[]\n",
    "\n",
    "        for item in text:\n",
    "            length.append(len(item))\n",
    "\n",
    "            for char in item:\n",
    "                if char in self.dict:\n",
    "                    label = self.dict[char]\n",
    "                else:\n",
    "                    label = 0\n",
    "                seq.append(label)\n",
    "        \n",
    "        return (torch.IntTensor(seq),torch.IntTensor(length))\n",
    "\n",
    "    def decode(self, seq, length):\n",
    "        '''Reverse the above conversion'''\n",
    "        seq_len = seq.numel() # return total no. of elements without multiplying dims\n",
    "        word_no = length.numel()\n",
    "\n",
    "        # word = []\n",
    "        text = []\n",
    "        \n",
    "        assert sum(length)==seq_len\n",
    "        start = 0\n",
    "        for i in range(word_no):\n",
    "            chars = []\n",
    "            for label in list(seq[start : start+length[i]]):\n",
    "                char = list(self.dict.keys())[list(self.dict.values()).index(label)]\n",
    "                chars.append(char)\n",
    "            word = ''.join(chars)\n",
    "            start += length[i]\n",
    "            text.append(word)\n",
    "        \n",
    "        return text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, '': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abb', 'cee', 'fga']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = 'abcdefg'\n",
    "\n",
    "samples = ['abb', 'cee', 'fga']\n",
    "\n",
    "converter = labelConverter(alphabet=alphabet)\n",
    "print(converter.dict)\n",
    "x,_ = converter.encode(samples)\n",
    "\n",
    "converter.decode(x,torch.IntTensor([3,3,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a3f9fbbaa18250e09d861f666ab05e97085a7241115cb1945ae796667bcb838e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
